# Example configuration for agent-cli
# Copy this file to ~/.config/agent-cli/config.toml or ./agent-cli-config.toml and edit
#
# This file demonstrates how to configure all available options.
# Keys use dashes to match the command-line arguments.
# Any option here can be overridden by a command-line argument.

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# --- Default Settings ---
# These settings apply to all commands unless overridden in a command-specific
# section below.
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[defaults]

# --- Provider Selection ---
# Select the default provider for each service ("local" or "openai").
llm-provider = "local"
asr-provider = "local"
tts-provider = "local"

# --- API Keys ---
# Your OpenAI API key. Can also be set via the OPENAI_API_KEY environment variable.
openai-api-key = "sk-..."

# --- Audio Device Settings ---
# You can specify partial names for devices, and the first match will be used.
# Use `agent-cli speak --list-devices` to see available devices.
input-device-name = "logitech,airpods"
output-device-name = "iloud,airpods,dell,macbook"
# You can also specify device by index, though name is more stable.
# input-device-index = 1
# output-device-index = 1

# --- LLM Settings ---
# Ollama (local)
llm-ollama-model = "qwen3:4b"
llm-ollama-host = "http://localhost:11434"
# OpenAI
llm-openai-model = "gpt-4o-mini"
# For llama-server (llama-cpp) or other OpenAI-compatible APIs:
# openai-base-url = "http://localhost:8080/v1"

# --- ASR (Speech-to-Text) Settings ---
# Wyoming (local)
asr-wyoming-ip = "localhost"
asr-wyoming-port = 10300
# OpenAI
asr-openai-model = "whisper-1"

# --- TTS (Text-to-Speech) Settings ---
# Wyoming (local)
tts-wyoming-ip = "localhost"
tts-wyoming-port = 10200
tts-wyoming-voice = "en_US-lessac-medium"
# tts-wyoming-language = "en_US"  # Optional: specify language for the voice
# tts-wyoming-speaker = "speaker_name" # Optional: specify speaker for the voice
# OpenAI
tts-openai-model = "tts-1"
tts-openai-voice = "alloy"

# --- General Behavior ---
log-level = "WARNING"  # Logging level (e.g., DEBUG, INFO, WARNING, ERROR)
# log-file = "/path/to/agent-cli.log" # Path to a file to write logs to
quiet = false # Suppress most console output
clipboard = true # Copy results to clipboard by default
# save-file = "/path/to/output.wav" # Save TTS audio to a file instead of playing


# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# --- Command-Specific Overrides ---
# Settings in these sections will override the [defaults] for that specific
# command.
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

[assistant]
# Wake-word specific settings
wake-server-ip = "localhost"
wake-server-port = 10400
wake-word = "ok_nabu" # e.g., "ok_nabu", "hey_jarvis"
# The assistant agent also uses ASR, LLM, and TTS settings from [defaults]
tts = true

[autocorrect]
# Use a more powerful model specifically for the autocorrect command.
llm-provider = "local"
llm-ollama-model = "devstral:24b"

[chat]
# By default, chat uses local providers.
# For better tool use, you might want to switch to OpenAI:
# llm-provider = "openai"
# tts-provider = "openai"
# llm-openai-model = "gpt-4-turbo"
tts = true
tts-speed = 1.2
# Conversation history settings
history-dir = "~/.config/agent-cli/history"
last-n-messages = 50 # Number of messages to load from history

[speak]
# Use a specific voice for the speak command.
tts-provider = "local"
tts-wyoming-voice = "en_US-ryan-high"
tts-speed = 1.0

[transcribe]
# By default, transcription uses local providers.
# For higher accuracy, you can switch to OpenAI:
# asr-provider = "openai"
# llm-provider = "openai"
# Enable LLM cleanup for the transcript.
llm = true
# Allow the user to provide additional instructions for the LLM.
extra-instructions = "Assume the user is often discussing Python programming. Use backticks for variable names, function names, and other code elements. Follow PEP8: use `snake_case` for variables, functions, and package names; `CamelCase` for classes. Other frequent words are `agent-cli`, `pipefunc`. My name is Bas Nijholt."

[voice-edit]
# Use a powerful local model for the voice assistant.
llm-provider = "local"
llm-ollama-model = "llama3"
tts = true
